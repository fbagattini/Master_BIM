{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Contenuti*\n",
    "===\n",
    "- [Scikit-learn: machine learning con Python](#Scikit-learn:-machine-learning-con-Python)\n",
    "    - [Un modello per la classificazione](#Un-modello-per-la-classificazione)\n",
    "        - [Dataset](#Dataset)\n",
    "        - [Insiemi di addestramento e test](#Insiemi-di-addestramento-e-test)\n",
    "        - [Addestramento](#Addestramento)\n",
    "        - [Predizione](#Predizione)\n",
    "        - [Valutazione](#Valutazione)\n",
    "    - [Feature scaling](#Feature-scaling)\n",
    "        - [*Esercizio 1*](#Esercizio-1)\n",
    "        - [*Esercizio 2*](#Esercizio-2)\n",
    "        - [*Esercizio 3*](#Esercizio-3)\n",
    "    - [Dai dati alla predizione in meno di quindici righe](#Dai-dati-alla-predizione-in-meno-di-quindici-righe)\n",
    "    - [Model selection](#Model-selection)\n",
    "        - [*Esercizio 4*](#Esercizio-4)\n",
    "        - [Cross-validation](#Cross-validation)\n",
    "    - [Alberi di decisione](#Alberi-di-decisione)\n",
    "    - [Regressione](#Regressione)\n",
    "        - [Metriche](#Metriche)\n",
    "        - [Overfitting](#Overfitting)\n",
    "    - [Metodi ensemble](#Metodi-ensemble)\n",
    "    - [SVM e SVR](#SVM-e-SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn: machine learning con Python\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Scikit-learn* (o *sklearn*) è uno dei principali strumenti Python per il machine learning, ed è la libreria open-source di data science più usata al mondo.\n",
    "\n",
    "Sulla pagina di sklearn, http://scikit-learn.org/stable/, si trovano svariati modelli di machine learning, insieme a strumenti di preprocessing, analisi e visualizzazione dei dati. \n",
    "\n",
    "Ciascuna implementazione fa riferimento ad una guida utente molto dettagliata, che associa al codice la teoria necessaria per capirlo ed usarlo: http://scikit-learn.org/stable/modules/classes.html.\n",
    "\n",
    "Oltre a permettere di *usare* il machine learning scrivendo pochissime righe di codice, la libreria è altamente modulare, e dà la possibilità agli utenti di costruire la propria implementazione basandosi su metodi, oggetti ed interfacce esistenti.\n",
    "\n",
    "Teoria e codice sono spesso supportati da esempi pratici di utilizzo, affiancati da analisi grafiche: http://scikit-learn.org/stable/auto_examples/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello per la classificazione\n",
    "---\n",
    "Costruiamo un modello $k$*-nearest neighbors* (KNN) per la classificazione, utilizzando l'implementazione sklearn *KNeighborsClassifier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'sklearn.neighbors' from '/home/frensis/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*neighbors* è un *modulo*, ovvero un insieme di oggetti e funzioni con caratteristiche comuni, impacchettati insieme.\n",
    "\n",
    "Se scriviamo\n",
    "\n",
    "                neighbors.\n",
    "                \n",
    "e premiamo il tasto di autocomplemento, possiamo dare un'occhiata agli oggetti contenuti nel modulo. Tra gli altri, vedremo KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo invocato un metodo speciale, chiamato *costrutture*, che inizializza (in questo caso senza parametri) un oggetto di tipo KNeighborsClassifier. Possiamo vedere\n",
    "\n",
    "- dalla documentazione: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "- posizionando il puntatore del mouse dentro le parentesi del costruttore e premendo Shift e due volte Tab\n",
    "- stampando l'oggetto creato,\n",
    "\n",
    "che questa implementazione del classificatore KNN prende in ingresso diversi parametri, nessuno dei quali obbligatorio. Per esempio, il numero di vicini $k$ (chiamato *n_neighbors*) vale di default 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "k: 3\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "print(model)\n",
    "print('k:', model.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Attraverso il modulo *datasets*, sklearn mette a disposizione diversi dataset, sui quali fare apprendimento e testare un modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print(type(iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il tipo *Bunch* è molto simile a un dizionario. Oltre alla matrice delle feature e al vettore delle etichette, troviamo anche qualche informazione sul dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "print(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Description: Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Labels:', iris['target_names'])\n",
    "print('\\nFeatures:', iris['feature_names'])\n",
    "print('\\nDescription:', iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1 3.5 1.4 0.2] 0\n",
      "[4.9 3.  1.4 0.2] 0\n",
      "[4.7 3.2 1.3 0.2] 0\n",
      "[4.6 3.1 1.5 0.2] 0\n",
      "[5.  3.6 1.4 0.2] 0\n",
      "[5.4 3.9 1.7 0.4] 0\n",
      "[4.6 3.4 1.4 0.3] 0\n",
      "[5.  3.4 1.5 0.2] 0\n",
      "[4.4 2.9 1.4 0.2] 0\n",
      "[4.9 3.1 1.5 0.1] 0\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(X[:10]) : print(x, y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 50 50]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np#alias per libreria importata\n",
    "\n",
    "print(np.bincount(y))#istogramma di occorrenza di valori interi in un array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insiemi di addestramento e test\n",
    "\n",
    "Dividiamo i dati in training e test set. Per prima cosa, mischiamo (coerentemente!) i dati in modo casuale col metodo *shuffle*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.8 2.8 5.1 2.4] 2\n",
      "[6.  2.2 4.  1. ] 1\n",
      "[5.5 4.2 1.4 0.2] 0\n",
      "[7.3 2.9 6.3 1.8] 2\n",
      "[5.  3.4 1.5 0.2] 0\n",
      "[6.3 3.3 6.  2.5] 2\n",
      "[5.  3.5 1.3 0.3] 0\n",
      "[6.7 3.1 4.7 1.5] 1\n",
      "[6.8 2.8 4.8 1.4] 1\n",
      "[6.1 2.8 4.  1.3] 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle#importo singola funzione dal modulo\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)#controllo del generatore random\n",
    "for i, x in enumerate(X[:10]) : print(x, y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo quindi due terzi degli esempi per l'addestramento, e i restanti per il test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (50, 4)\n"
     ]
    }
   ],
   "source": [
    "n_train = int(2*X.shape[0]/3)\n",
    "X_train = X[:n_train]#i primi n_train esempi (righe)\n",
    "X_test = X[n_train:]#gli altri\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente per le etichette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (50,)\n"
     ]
    }
   ],
   "source": [
    "y_train, y_test = y[:n_train], y[n_train:]#doppia assegnazione\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addestramento\n",
    "\n",
    "Tramite il metodo *fit* addestriamo il modello sui dati di apprendimento. Il metodo opera in-place e retituisce il modello addestrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "print(model.fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predizione\n",
    "\n",
    "Una volta addestrato, usiamo il modello per predire la classe degli esempi del test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Must fit neighbors before querying.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-027404650b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must fit neighbors before querying.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: Must fit neighbors before querying."
     ]
    }
   ],
   "source": [
    "neighbors.KNeighborsClassifier().predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valutazione\n",
    "\n",
    "Infine, valutiamo le prestazioni (per esempio, l'accuratezza) del modello addestrato sull'insieme di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy on test set:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predizione e valutazione possone essere fatte in un colpo solo, grazie al metodo *score* esposto dal modello (addestrato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy on test set:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling\n",
    "---\n",
    "Torniamo un attimo indietro e *normalizziamo* i dati prima di addestrare il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Esercizio 1*\n",
    "Scaricare il dataset *iris* ed estrarre, per ogni feature, i valori minimo e massimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Esercizio 2*\n",
    "Costruire un array *X_scaled*, contenente gli stessi esempi del dataset di partenza, con le feature scalate tra 0 e 1. Verificare che i valori minimo e massimo di ogni feature siano effettivamente 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tra gli strumenti di preprocessing di sklearn, troviamo alcune utilità per scalare le feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.feature_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "print(np.min(X_scaled, axis=0))\n",
    "print(np.max(X_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il metodo *fit_transform* opera due passi in sequenza, *fit* e *transform*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "print(np.min(X_scaled, axis=0))\n",
    "print(np.max(X_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attenzione**: anche lo scaling viene \"addestrato\" sui dati, come si vede dal nome del metodo fit. In particolare, lo scaler impara i valori minimo e massimo di ogni feature, che userà nella successiva trasformazione.\n",
    "\n",
    "In un contesto operativo, questa fase (come l'addestramento vero e proprio) viene affrontata senza conoscere il test set. Trasformiamo quindi il test set *dopo* aver fittato il train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)#già fittato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalente a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ripetiamo quindi i passi di addestramento e test (= predizione+valutazione) con i dati normalizzati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train)#addestramento\n",
    "print('Model accuracy on test set:', model.score(X_test_scaled, y_test))#test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Esercizio 3*\n",
    "\n",
    "Utilizzare lo *StandardScaler* del modulo preprocessing per scalare le feature del dataset iris a media 0 e varianza 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#FILL ME\n",
    "print(StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dai dati alla predizione in meno di quindici righe\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco tutto quello che ci serve, con sklearn, per costruire un modello di classificazione a partire da un dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "#Importo librerie\n",
    "from sklearn import datasets, neighbors\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Carico il dataset\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "\n",
    "#Separo train e test (si può fare in una riga sola!)\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "n_train = int(2*X.shape[0]/3)\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "\n",
    "#Scalo le feature tra 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Addestro il modello\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "\n",
    "#Valuto l'accuratezza del modello\n",
    "print('Model accuracy on test set:', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection\n",
    "---\n",
    "Calibriamo adesso il valore dell'*iper-parametro* $k$. Abbiamo bisogno di una procedura di validazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Esercizio 4*\n",
    "Utilizzando gli oggetti e i metodi sklearn visti in precedenza, \n",
    "\n",
    "- caricare feature ed etichette del dataset *digits*: http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
    "- separare i dati (dopo averli mischiati, con seed=123) in questo modo:\n",
    "    * 500 esempi per l'addestramento\n",
    "    * 500 per la validazione\n",
    "    * il resto per il test\n",
    "- scalare i dati a media 0 e varianza 1\n",
    "- costruire una griglia di valori di $k$: $\\left[1,2,3,5,10\\right]$\n",
    "- scegliere il valore della griglia che (produce il modello KNN che) registra la maggiore accuratezza sul validation set\n",
    "- addestrare nuovamente KNN, usando gli esempi degli insiemi di addestramento e validazione e il valore di $k$ scelto\n",
    "- calcolare l'accuratezza del modello ottenuto sull'insieme di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Carico il dataset\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits['data'], digits['target']\n",
    "\n",
    "#Separo train e test\n",
    "X, y = shuffle(X, y, random_state=123)\n",
    "#FILL ME\n",
    "\n",
    "#Valuto accuratezza dei modelli sul set di validazione\n",
    "#FILL ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Rifitto su tutto il training set\n",
    "#FILL ME\n",
    "\n",
    "#Valuto accuratezza del miglior modello sul test set\n",
    "#FILL ME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Per schemi di validazione più complessi di quello visto nell'esercizio precedente, possiamo usare il modulo *model_selection*. Facciamo ad esempio una $k$*-fold cross-validation* (KCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated value for k: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import GridSearchCV as KCV\n",
    "\n",
    "#carico iris e separo train da test...\n",
    "\n",
    "model = KNN()#modello da validare\n",
    "param_grid = [{'n_neighbors' : [1,2,3,5,10,20]}]#griglia dei valori degli iperparametri\n",
    "n_folds = 5#K, numero dei fold\n",
    "#volendo, posso scegliere una metrica (campo 'scoring') diversa dall'accuratezza\n",
    "\n",
    "kcv = KCV(model, param_grid, cv=n_folds)#oggetto validatore\n",
    "kcv.fit(X_train, y_train)#fitto come un modello\n",
    "best_model = kcv.best_estimator_#estraggo modello con comportamento medio migliore\n",
    "\n",
    "print('Validated value for k:', best_model.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si può esplorare lo schema di validazione creato attraverso il tipo *GridSearchCV* scrivendo\n",
    "        \n",
    "        kcv.\n",
    "        \n",
    "e premendo Tab. In particolare, il campo *cv_results_* contiene il dettaglio dei punteggi ottenuti sui vari fold dai modelli (iper)parametrizzati da $k$.\n",
    "\n",
    "Come al solito, è possibile condensare tutta l'operazione in un'unica riga di codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated value for k: 10\n"
     ]
    }
   ],
   "source": [
    "best_model = KCV(KNN(),\n",
    "                 [{'n_neighbors' : [1,2,3,5,10,20]}],\n",
    "                 cv=5).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "print('Validated value for k:', best_model.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alberi di decisione\n",
    "---\n",
    "Costruiamo adesso un *albero di decisione* (DT) ed utilizziamolo per la classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Carico il dataset\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "\n",
    "#Separo train e test (in modo compatto)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "\n",
    "#Addestro il modello\n",
    "model = DT()\n",
    "model.fit(X_train, y_train)\n",
    "print('Accuracy on test set: {:.2f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come è fatto internamente un DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\n",
      "Split criterion: gini\n",
      "Max depth: None\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print('\\nSplit criterion:', model.criterion)\n",
    "print('Max depth:', model.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco un esempio di validazione KCV su DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated criterion: gini\n",
      "Validated max depth: 3\n",
      "Validated model accuracy on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "best_model = KCV(DT(),\n",
    "                 param_grid=[{'criterion' : ['gini', 'entropy'],\n",
    "                              'max_depth' : [2, 3, 5, 10, 50]}],\n",
    "                 cv=3).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "print('Validated criterion:', best_model.criterion)\n",
    "print('Validated max depth:', best_model.max_depth)\n",
    "print('Validated model accuracy on test set: {:.2f}'.format(best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una funzionalità del modulo *tree* (basata su http://www.graphviz.org/) permette di esportare un albero addestrato in formato grafico. Qui un esempio completo: http://scikit-learn.org/stable/modules/tree.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressione\n",
    "---\n",
    "In un task di *regressione*, le etichette da apprendere sono valori numerici continui. Scikit-learn fornisce un'implementazione per la regressione sia per KNN che per DT:\n",
    "\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "\n",
    "La struttura degli modelli è molto simile a quella vista per la classificazione. Vediamo un esempio di regressione KNN sul dataset *boston housing*: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston['data'], boston['target']\n",
    "\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodness of fit on test set: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "\n",
    "#Separo train e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)#schema base di validazione\n",
    "\n",
    "#Scalo i dati tra 0 e 1\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Addestro KNN e lo testo\n",
    "model = KNN(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "print('Goodness of fit on test set: {:.2f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metriche\n",
    "\n",
    "Che cosa misura il valore 0.67?\n",
    "\n",
    "Ciascun task ha uno *scorer* di default. Nel caso della classificazione, il punteggio di un modello indica la sua accuratezza. Per quanto riguarda la regressione, la metrica di default è il *coefficiente di determinazione* ($\\text{R}^2$), https://en.wikipedia.org/wiki/Coefficient_of_determination.\n",
    "\n",
    "Se vogliamo utilizzare una metrica diversa, possiamo usare il modulo *metrics*: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.\n",
    "\n",
    "Usiamo ad esempio il *mean absolute error* (MAE):\n",
    "\n",
    "$$MAE(M, X^{test}, y^{test}) := \\frac{1}{n_{test}} \\sum_{i=1}^{n_{test}} \\hspace{.15cm} \\lvert M(X^{test}_i) - y^{test}_i\\rvert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test set: 3.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "mae = MAE(y_test, model.predict(X_test))\n",
    "print('MAE on test set: {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "\n",
    "Sempre riguardo al task di regressione, vediamo un esempio di *overfitting* con DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes dataset\n",
      "================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "Data Set Characteristics:\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attributes:\n",
      "    :Age:\n",
      "    :Sex:\n",
      "    :Body mass index:\n",
      "    :Average blood pressure:\n",
      "    :S1:\n",
      "    :S2:\n",
      "    :S3:\n",
      "    :S4:\n",
      "    :S5:\n",
      "    :S6:\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "print(diabetes['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(diabetes['target'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test set: -0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as DT\n",
    "\n",
    "X, y = diabetes['data'], diabetes['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "\n",
    "model = DT(random_state=123)#componente di randomicità\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('R2 on test set: {:.2f}'.format(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il punteggio ($\\text{R}^2$) ottenuto sull'insieme di test è molto basso. Cosa è successo? Proviamo a valutare le prestazioni del modello sull'insieme di apprendimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on training: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('R2 on training: {:.2f}'.format(model.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il punteggio sul training set è massimo: abbiamo commesso overfitting. Il modello che abbiamo scelto ha fittato con troppa precisione i dati di apprendimento, perdendo la sua capacità di generalizzazione.\n",
    "\n",
    "Proviamo a rimediare validando la profondità di sviluppo (*max_depth* in sklearn), uno degli iperparametri di un DT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated max_depth: 2\n",
      "\n",
      "R2 on training/test set: 0.49/0.21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV as KCV\n",
    "\n",
    "kcv = KCV(DT(),\n",
    "          param_grid=[{'max_depth':[2,3,5,10,20,50,None]}],\n",
    "          cv=5).fit(X_train, y_train)\n",
    "\n",
    "best_model = kcv.best_estimator_\n",
    "\n",
    "print('Validated max_depth:', best_model.max_depth)\n",
    "print('\\nR2 on training/test set: {:.2f}/{:.2f}'.format(best_model.score(X_train, y_train),\n",
    "                                                        best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche se non abbiamo ottenuto un risultato eccellente, è diminuito il divario tra i punteggi ottenuti su training e test set: questo è indice di un modello con una migliore capacità di generalizzazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodi ensemble\n",
    "---\n",
    "Vediamo adesso un *ensemble*, l'implementazione sklearn di una *random forest* (RF). \n",
    "\n",
    "Questo modello è un esempio di *bagging*, uno schema in cui le predizioni di singoli modelli indipendenti e di alta complessità vengono fatte votare (classificazione) o mediate (regressione), con lo scopo di aumentarne la capacità di generalizzazione.\n",
    "\n",
    "Addestriamo e testiamo RF sul dataset *digit*, un'instanza di classificazione multi-classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le classi del dataset digit sono i numeri da 0 a 9. Il task riguarda infatti la decodifica automatica di cifre scritte a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importiamo, dal modulo *ensemble*, l'implementazione RF per la regressione: *RandomForestClassifier*.\n",
    "\n",
    "Vediamo quali sono le caratteristiche strutturali del modello, e distinguiamo quelle proprie dello schema ensemble da quelle dei singoli alberi che compongono la foresta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "DT hyperparameters:\n",
      "- impurity criterion: gini\n",
      "- max depth of development: None\n",
      "- max features sampled at each node: auto\n",
      "\n",
      "Ensemble hyperparameters:\n",
      "- number of trees: 10\n",
      "- replacement? True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "\n",
    "model = RF()\n",
    "print(model)\n",
    "\n",
    "print('\\nDT hyperparameters:')\n",
    "print('- impurity criterion:', model.criterion)\n",
    "print('- max depth of development:', model.max_depth)\n",
    "print('- max features sampled at each node:', model.max_features)\n",
    "\n",
    "print('\\nEnsemble hyperparameters:')\n",
    "print('- number of trees:', model.n_estimators)\n",
    "print('- replacement?', model.bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costruiamo gli insiemi di addestramento e test e validiamo il campo *max_features*. Il valore di questo iperparametro indica la dimensione del sottoinsieme casuale di features nel quale si cerca il migliore split. \n",
    "\n",
    "Questa strategia differenzia RF da *bagged trees*, altro schema ensemble basato su DT. A causa della componente random introdotta da max_features, il *bias* dei singoli alberi cresce. Questo  fenomeno è però dominato dalla riduzione in *varianza* dovuta (alla randomicità e) al voto combinato.\n",
    "\n",
    "Nel bagging, i singoli modelli che vengono combinati nell'ensemble hanno alta complessità. RF, in particolare, lavora con DT *fully developed*. Inoltre, poichè lo scopo è quello di ridurre il bias dell'ensemble grazie al voto a maggioranza, è preferibile un numero più grande possibile di alberi.\n",
    "\n",
    "In breve, l'unico iperparametro che (secondo l'autore di queste lezioni) vale la pena di validare è il numero di feature da valutare ad ogni nodo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated max_features : 10\n",
      "Accuracy on test set   : 0.98\n"
     ]
    }
   ],
   "source": [
    "X, y = digits['data'], digits['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)\n",
    "\n",
    "best_model = KCV(RF(n_estimators=1000,#the more the better!\n",
    "                    max_depth=None),#fully developed!\n",
    "                 param_grid=[{'max_features' : [2, 3, 5, 10, 30, 50, None]}],\n",
    "                 cv=3).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "print('Validated max_features :', best_model.max_features)\n",
    "print('Accuracy on test set   : {:.2f}'.format(best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC e SVR\n",
    "---\n",
    "Per finire, vediamo le implementazioni sklearn del modello *support vector machine*. Usiamo il dataset *breast_cancer*, e risolviamo il relativo problema di classificazione binaria con l'implementazione *SVC*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign'] [212 357]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer['target_names'], np.bincount(cancer['target']))\n",
    "\n",
    "X, y = cancer['data'], cancer['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "model = SVC()#support vector classification\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di default, SVC usa un *kernel gaussiano* (indicato con *rbf*). Validiamo gli iperparametri $C$ e $\\gamma$: questi denotano rispettivamente il peso dato agli errori commessi sui singoli esempi e l'inverso della deviazione standard $\\sigma$ della gaussiana \"montata\" su ogni esempio dal kernel gaussiano.\n",
    "\n",
    "Per entrambi gli iperparametri, valori troppo alti possono causare overfitting. Viceversa, valori troppo bassi possono produrre modelli eccessivamente semplici, non sufficienti a \"spiegare\" i dati. Ecco cosa succede, ad esempio, se assegno un valore molto grande a $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train/test: 1.00/0.63\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=100000).fit(X_train, y_train)\n",
    "print('Accuracy on train/test: {:.2f}/{:.2f}'.format(model.score(X_train, y_train),\n",
    "                                                     model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono diverse ricette di validazione per $C$ e $\\gamma$, sia per la classificazione che per la regressione: ad esempio, si possono assegnare potenze contigue del 2 o del 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125, 0.25, 0.5, 1, 2, 4]\n",
      "[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n"
     ]
    }
   ],
   "source": [
    "C_values = [2**i for i in range(-3,3)]\n",
    "gamma_values = [10**i for i in range(-3,4)]\n",
    "print(C_values)\n",
    "print(gamma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta costruita la griglia, cerchiamo la migliore coppia di valori con KCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated C            : 2\n",
      "Validated gamma        : 0.001\n",
      "Validated accuracy on train/test: 0.99/0.92\n"
     ]
    }
   ],
   "source": [
    "best_model = KCV(SVC(),\n",
    "                 param_grid=[{'C': C_values,\n",
    "                              'gamma': gamma_values}],\n",
    "                 cv=3).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "print('Validated C            :', best_model.C)\n",
    "print('Validated gamma        :', best_model.gamma)\n",
    "print('Validated accuracy on train/test: {:.2f}/{:.2f}'.format(best_model.score(X_train, y_train),\n",
    "                                                               best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nell'esempio successivo, vogliamo provare due diverse griglie di iperparametri. In particolare:\n",
    "\n",
    "- il valore di $C$ con un kernel lineare\n",
    "- il valore di $C$ con un kernel gaussiano, per cui voglio validare anche $\\gamma$.\n",
    "\n",
    "Perchè è più conveniente usare due griglie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated kernel       : linear\n",
      "Validated C            : 4\n",
      "Validated gamma        : auto\n",
      "Validated accuracy on test set   : 0.96\n"
     ]
    }
   ],
   "source": [
    "best_model = KCV(SVC(),\n",
    "                 param_grid=[{'kernel':['linear'],\n",
    "                              'C': C_values},#prima griglia\n",
    "                             {'kernel':['rbf'],\n",
    "                              'C': C_values,\n",
    "                              'gamma': gamma_values}],#seconda griglia\n",
    "                 cv=3).fit(X_train, y_train).best_estimator_\n",
    "\n",
    "print('Validated kernel       :', best_model.kernel)\n",
    "print('Validated C            :', best_model.C)\n",
    "print('Validated gamma        :', best_model.gamma)\n",
    "print('Validated accuracy on test set   : {:.2f}'.format(best_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infine, l'implementazione sklearn di SVM per la regressione è $SVR$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "print(SVR())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('div.prompt').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter, delivered by Fastly, rendered by Rackspace.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
